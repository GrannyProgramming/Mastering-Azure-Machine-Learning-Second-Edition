{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset from Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by loading version 2 of our dataset, where we did not convert everything into numerical values yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "dataset_name = 'Melbourne Housing Dataset'\n",
    "\n",
    "# Get a dataset by name\n",
    "melb_ds = Dataset.get_by_name(workspace=ws, name=dataset_name, version=2)\n",
    "\n",
    "# Load a TabularDataset into pandas DataFrame\n",
    "df = melb_ds.to_pandas_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us remember our preliminary results from Chapter 5 (Feature Importance for target Price and Price_log):\n",
    "\n",
    "![alt text](feature_chap5.png \"Feature Importance for Price and log(Price)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us talk about these results a bit further than we did in Chapter 5. For that, let us group these feature into what they actually convey.\n",
    "\n",
    "**Housing Properties**\n",
    "- Type: seems to have a very high indication for price. It is also helpful, that there are only 3 possible \"settings\" for this feature.\n",
    "- Parking: Having 5 or 7 parking spaces is probably not a big difference anymore. We could have a look at making this more discrete by dividing it into maybe three groups 0, 1 and 2+ parking spaces for example.\n",
    "- YearBuilt: From our understanding, the age of a house should have an impact on the price, yet it seems very small. We could transform the data into a discrete age 0-10, 10-20, 20-30 etc.\n",
    "- BuildingArea: One would think, this should have a much higher influence. Therefore, let us divide this as well into groups.\n",
    "- Landsize: Same argument as BuildingArea.\n",
    "- Bathrooms, Bedrooms, Rooms: We would have to drill down deeper into these. As seen before, there seem to be some questionable combinations. Still this has some impact on the price (as we would expect).\n",
    "\n",
    "**Housing Location**\n",
    "- Suburb: As predicted, suburb has too many possible values (around 500) to be of much use. Therefore, we will ignore this as well for now.\n",
    "- SuburbPropCount: Once again, this value is too detailed and therefore does not seems to have nearly no predictive value. Once again, we could think of building a discrete feature breaking it in 3-5 groups.\n",
    "- CouncilArea: has some impact, but we see it dwindleds when looking at the logarithmic price.\n",
    "- Distance (from city center): seems to have a high impact and could be improved by discretization.\n",
    "- Region: draws a clearer picture for the price compared to CouncilArea or suburb.\n",
    "- Longitude&Lattitude: Seems to have a high impact. They seem to convey something better than the CouncilArea.\n",
    "\n",
    "**Others**\n",
    "- Method: The method how the house or apartment is bought seems to have not much importance, as we would presume in most cases. Therefore, we can remove this certainly.\n",
    "- Date: (not included in the Feature Importance graph) The sell date over a couple of years. We might find a small increase due to constantly increasing housing prices, if we only look at the year. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at histograms of all the features we might want to transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(df, x=\"Parking\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, that we replaced the missing values with the median = 2, therefore be advised, that the most properties probably have 1 parking spot. As discussed, we could bin these into 0, 1, 2++ groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YearBuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(df, x=\"YearBuilt\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see our missing values create a spike in the middle of the dataset. Equal binning of 10 year spans might be a good starting point. Let us have a look at that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "counts, bins = np.histogram(df[\"YearBuilt\"], bins=range(1850, 2030, 10))\n",
    "bins = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "fig = px.bar(x=bins, y=counts, labels={'x':'Distance', 'y':'count'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BuildingArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(df, x=\"BuildingArea\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also here, we can see our missing value replacement for the building area. Using equidistant bins might be of interest here as well. Let us look at that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "counts, bins = np.histogram(df[\"BuildingArea\"], bins=range(0, 350, 25))\n",
    "bins = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "fig = px.bar(x=bins, y=counts, labels={'x':'Distance', 'y':'count'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(df, x=\"Distance\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An equal distance binning with steps of 5 miles could be an option here. Let's have a look at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "counts, bins = np.histogram(df[\"Distance\"], bins=range(0, 60, 5))\n",
    "bins = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "fig = px.bar(x=bins, y=counts, labels={'x':'Distance', 'y':'count'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CouncilArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(df, x=\"CouncilArea\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An option here could be to fill out the missing CouncilAreas. We have street addresses for all of them, so either pulling in external data or checking the suburbs to CouncilArea matching should give us the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(df, x=\"Region\",)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this, we could combine the houses outside of the metropolitan area into one group (Victoria) or we could even create only two groups (Metropolitan, Victoria)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df[\"Year Offered/Sold\"] = df['Date'].dt.year.astype(int)\n",
    "\n",
    "fig = px.histogram(df, x=\"Year Offered/Sold\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we presumed, the data is taken during two years (2016 and 2017)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SuburbPropCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(df, x=\"SuburbPropCount\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a lot of different amounts here. Once again, binning might be helpful. For example doing bins with a size of 5000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "counts, bins = np.histogram(df[\"SuburbPropCount\"], bins=range(0, 25000, 5000))\n",
    "bins = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "fig = px.bar(x=bins, y=counts, labels={'x':'SuburbPropCount', 'y':'count'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a much cleaner result and with 4 bins might actually have some predictive property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to do next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first view on the data should give you some ideas to think about. What to do next is create new transformed features from the original ones and run the feature importance again. As this process is done through a random forest, you are using already a useful baseline model. You could also just start testing your dataset on a random forest directly, by creating at least a test and training split of the data here and use a cost function to measure your success.\n",
    "\n",
    "We leave you with our suggestions, what you might want to transform and test again. \n",
    "\n",
    "*For this, it is probably wise to load version 1 of the dataset, as we will have a look at the missing values again in step 3*\n",
    "\n",
    "**1. Discretization**\n",
    "\n",
    "Create new transformed features for the following:\n",
    "- SuburbPropCount\n",
    "- Region\n",
    "- Distance\n",
    "- Landsize\n",
    "\n",
    "**2. Rooms, Bathrooms, Bedrooms**\n",
    "\n",
    "You might have seen, that there are some discrepencies between Rooms vs. Bathrooms/Bedrooms. This data was extracted from an Austrialian appartment/house selling platform. It might be the case, which means the seller provides this information. Therefore, the two obvious options might be, that:\n",
    "- Rooms = Bathrooms + Bedrooms\n",
    "- Rooms = Bedrooms\n",
    "\n",
    "Looking at the head of the dataset above, one of those rules might be true. Write a function, that groups the dataset into the entries that follow rule 1, the entries that follow rule 2 and anything that does not follow these rules. Then make the decision to change this into either direction. Probably rule 1 is the most useful.\n",
    "\n",
    "**3. Missing Values**\n",
    "\n",
    "Having done the above, we now have a better chance to group our samples, which in turn can help us to replace our missing values not with the mean or median of the entire dataset, but with the one defining a group of samples. As an example, we could group by (Type, Distance, Region, Rooms) to calculate for each of the group the mean for BuildingArea. This requires a bunch of code, but gives a more realistic statistical property for the samples with missing values.\n",
    "In addition, we can the missing CouncilAreas, by checking which CouncilArea is written for the suburb in other samples.\n",
    "\n",
    "**4. Discretization Part 2**\n",
    "\n",
    "After that, we can start binning the leftover values:\n",
    "- BuldingArea\n",
    "- YearBuilt\n",
    "- Parking\n",
    "\n",
    "**5. Lattitude/Longitude**\n",
    "\n",
    "It is interesting to see, that Lat/Long already has a reasonable predictive value, even though it is a list of a lot of different numerical values. There are a lot of things that can be done with geospatial coordinates. Just to give you an idea: Maybe you have a property in an expensive suburb, but your small area is next to something that influences the price (industrial plant, loud school, church, ...). Therefore, bringing in more information about the location around the property might be of interest. You can find some external datasets for Melbourne here: https://data.melbourne.vic.gov.au/\n",
    "\n",
    "\n",
    "*Enjoy the data crunching*"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8cf0ba5c97d8213a473c3c3809ce96b11278674036cd7196aea1f6db1086a4f2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
