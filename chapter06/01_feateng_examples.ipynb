{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation for Datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let'S create a dataframe for the measurement of cars passing on a street."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'time of measurement': pd.date_range(start='2021-01-01 11:00', freq='24H', periods=7), \n",
    "     'number of cars': [60, 412, 230, 1234, 854, 1432, 1103]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us add the day of the week of those chosen measurement days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day of the week'] = df[\"time of measurement\"].dt.day_name()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us add a new field called daytype, which describes if it is a workday, a holiday or a weekend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['daytype'] = df['day of the week'].isin(['Saturday', 'Sunday'])\n",
    "df[\"daytype\"].replace({False: 'weekday', True: 'weekend'}, inplace=True)\n",
    "df.loc[0,\"daytype\"]=\"holiday\"\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us convert the daytype feature into a one-hot encoding feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot = pd.get_dummies(df.daytype)\n",
    "df_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us add the one-hot encoded feature to the original table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([df,df_onehot],axis=1)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us load the original melbourne housing dataset from storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from azureml.core import Datastore, Dataset\n",
    "\n",
    "\n",
    "# retrieve an existing datastore in the workspace by name\n",
    "datastore_name = 'mldemoblob'\n",
    "datastore = Datastore.get(ws, datastore_name)\n",
    "\n",
    "# create a TabularDataset from the file path in datastore\n",
    "datastore_path = [(datastore, 'melb_data.csv')]\n",
    "tabdf = Dataset.Tabular.from_delimited_files(path=datastore_path)\n",
    "\n",
    "# create panda dataframe\n",
    "raw_df = tabdf.to_pandas_dataframe()\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us concentrate on the feature BuildingArea and the target Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df[{\"BuildingArea\",\"Price\"}].dropna(how='any')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us use the StandardScaler to create scaled versions of BuildingArea and Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdscaler = StandardScaler()\n",
    "stdscaler.fit(df)\n",
    "stdscalerarray = stdscaler.transform(df)\n",
    "stdscaled_df = pd.DataFrame(stdscalerarray, columns = [\"StdSc(Price)\", \"StdSc(BuildingArea)\"])\n",
    "stdscaled_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaled_df.boxplot(figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us do the same with the MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler = MinMaxScaler()\n",
    "mmscaler.fit(df)\n",
    "mmscalerarray = mmscaler.transform(df)\n",
    "mmscaled_df = pd.DataFrame(mmscalerarray, columns = [\"MinMaxSc(Price)\", \"MinMaxSc(BuildingArea)\"])\n",
    "mmscaled_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmscaled_df.boxplot(figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and with the RobustScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "robscaler = RobustScaler()\n",
    "robscaler.fit(df)\n",
    "robscalerarray = robscaler.transform(df)\n",
    "robscaled_df = pd.DataFrame(robscalerarray, columns = [\"RobustSc(Price)\", \"RobustSc(BuildingArea)\"])\n",
    "robscaled_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robscaled_df.boxplot(figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us incorporate all the scaled versions into the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = pd.concat([df,stdscaled_df,mmscaled_df,robscaled_df],axis=1)\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and have a look at there statistical properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_price_df = scaled_df[[\"Price\", \"StdSc(Price)\",\"MinMaxSc(Price)\",\"RobustSc(Price)\"]]\n",
    "dist_only_price_df = only_price_df.describe().T.apply(lambda s: s.apply(lambda x: format(x, 'g')))\n",
    "dist_only_price_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the standard scaler has a mean of 0 and a std deviation of 1, where as the minmax scaler has a minimum value of 0 and a maximum value of 1 and finally the robust scaler has a median of 0. See also the plots below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_price_df = scaled_df[[\"MinMaxSc(Price)\"]]\n",
    "scaled_price_df.boxplot(figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_price_df = scaled_df[[\"StdSc(Price)\", \"RobustSc(Price)\"]]\n",
    "scaled_price_df.boxplot(figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us create a dataframe using the data in the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_df = pd.read_csv(r'.\\favoritesnacks.csv')\n",
    "enc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us add a new feature for count enconding, where we count the amount of snacks in the whole sample set and add this as a feature value for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntenc = (enc_df.groupby(\"Favorite Snack\").size())\n",
    "enc_df['CntEnc(FavSnack)'] = enc_df[\"Favorite Snack\"].apply(lambda x : cntenc[x])\n",
    "enc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us do the same using frequency encoding, which does not show the absolute, but the relative amount for each snack item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frenc = (enc_df.groupby(\"Favorite Snack\").size()) / len(enc_df)\n",
    "enc_df['FreqEnc(FavSnack)'] = enc_df[\"Favorite Snack\"].apply(lambda x : frenc[x])\n",
    "enc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us use a package called category_encoders, which implements a target encoding algorithm to add the final encoder type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install category_encoders\n",
    "from category_encoders import TargetEncoder\n",
    "encoder = TargetEncoder()\n",
    "enc_df[\"TargetEnc(FavSnack)\"] = encoder.fit_transform(enc_df[\"Favorite Snack\"],enc_df[\"Likelihood to Buy\"])\n",
    "enc_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8cf0ba5c97d8213a473c3c3809ce96b11278674036cd7196aea1f6db1086a4f2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
