{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Configure experiment\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "# Create or get training cluster\n",
    "aml_cluster = get_aml_cluster(ws, cluster_name=\"cpu-cluster\")\n",
    "aml_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a run configuration\n",
    "run_conf = get_run_config(['numpy', 'pandas', 'scikit-learn', 'tensorflow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, name='titanic')\n",
    "data_in = dataset.as_named_input('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "datastore = Datastore.get(ws, datastore_name=\"mldata\")\n",
    "data_train = PipelineData('train', datastore=datastore)\n",
    "data_test = PipelineData('test', datastore=datastore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data import OutputFileDatasetConfig\n",
    "\n",
    "data_out = OutputFileDatasetConfig(name=\"predictions\", destination=(datastore, 'titanic/predictions'))\n",
    "data_out = data_out.read_delimited_files().register_on_complete('titanic.pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "step_1 = PythonScriptStep(name='Preprocessing',\n",
    "                          script_name=\"preprocess_output.py\",\n",
    "                          source_directory=\"code\",\n",
    "                          arguments=[\n",
    "                              \"--input\", data_in,\n",
    "                              \"--out-train\", data_train,\n",
    "                              \"--out-test\", data_test],\n",
    "                          inputs=[data_in],\n",
    "                          outputs=[data_train, data_test],\n",
    "                          runconfig=run_conf,\n",
    "                          compute_target=aml_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "step_2 = PythonScriptStep(name='Training',\n",
    "                          script_name=\"train_output.py\",\n",
    "                          source_directory=\"code\",\n",
    "                          arguments=[\n",
    "                              \"--in-train\", data_train,\n",
    "                              \"--in-test\", data_test,\n",
    "                              \"--output\", data_out],\n",
    "                          inputs=[data_train, data_test],\n",
    "                          outputs=[data_out],\n",
    "                          runconfig=run_conf,\n",
    "                          compute_target=aml_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(ws, steps=[step_1, step_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: AzureML Published Pipeline, id: 8ce894d6-5aea-406e-9669-d0edbe6eb19e\n",
      "name: AzureML Published Pipeline, id: b67b39ba-04fd-43ed-8351-bc4046608d6b\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import PublishedPipeline\n",
    "\n",
    "for pipeline in PublishedPipeline.list(ws):\n",
    "    print(\"name: %s, id: %s\" % (pipeline.name, pipeline.id))\n",
    "\n",
    "pipeline = PublishedPipeline.list(ws)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule\n",
    "\n",
    "recurrence = ScheduleRecurrence(frequency=\"Minute\", interval=15)\n",
    "\n",
    "schedule = Schedule.create(ws,\n",
    "                           name=\"AzureML Scheduled Pipeline\", \n",
    "                           pipeline_id=pipeline.id,\n",
    "                           experiment_name=\"azureml-pipeline-schedule\", \n",
    "                           recurrence=recurrence,\n",
    "                           pipeline_parameters={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schedule.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c39ce73b6d48f343ffd00681afb9b3f63104480cfaffe0ebb445fe41a6801158"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('packt-repo-M2qY5kM-': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
