{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "os.makedirs('./data/mnist', exist_ok=True)\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', filename = './data/mnist/train-images.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', filename = './data/mnist/train-labels.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', filename = './data/mnist/test-images.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', filename = './data/mnist/test-labels.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#src: https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training-with-deep-learning/train-hyperparameter-tune-deploy-with-keras/utils.py\n",
    "import gzip\n",
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "# load compressed MNIST gz files and return numpy arrays\n",
    "def load(filename, label=False):\n",
    "    with gzip.open(filename) as gz:\n",
    "        struct.unpack('I', gz.read(4))\n",
    "        n_items = struct.unpack('>I', gz.read(4))\n",
    "        if not label:\n",
    "            n_rows = struct.unpack('>I', gz.read(4))[0]\n",
    "            n_cols = struct.unpack('>I', gz.read(4))[0]\n",
    "            res = np.frombuffer(gz.read(n_items[0] * n_rows * n_cols), dtype=np.uint8)\n",
    "            res = res.reshape(n_items[0], n_rows * n_cols)\n",
    "        else:\n",
    "            res = np.frombuffer(gz.read(n_items[0]), dtype=np.uint8)\n",
    "            res = res.reshape(n_items[0], 1)\n",
    "    return res\n",
    "\n",
    "def one_hot_encode(array, num_of_classes):\n",
    "    return np.eye(num_of_classes)[array.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load('./data/mnist/train-images.gz', False) / 255.0\n",
    "X_test = load('./data/mnist/test-images.gz', False) / 255.0\n",
    "y_train = load('./data/mnist/train-labels.gz', True).reshape(-1)\n",
    "y_test = load('./data/mnist/test-labels.gz', True).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "num_train_samples = len(X_train)\n",
    "num_test_samples = len(X_test)\n",
    "\n",
    "X_train = X_train.reshape((num_train_samples,28,28,1))\n",
    "X_test = X_test.reshape((num_test_samples,28,28,1))\n",
    "y_train = one_hot_encode(y_train, num_classes)\n",
    "y_test = one_hot_encode(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_path = \"./mnist_cnn.bin\"\n",
    "checkpoint_cb = ModelCheckpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=16, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(checkpoint_path)\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c39ce73b6d48f343ffd00681afb9b3f63104480cfaffe0ebb445fe41a6801158"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('packt-repo-M2qY5kM-': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
