{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "# Experiment name\n",
    "exp_name = \"titanic-lgbm\"\n",
    "\n",
    "# Configure experiment\n",
    "ws = Workspace.from_config()\n",
    "exp = Experiment(workspace=ws, name=exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PassengerId'], axis=1, inplace=True)\n",
    "\n",
    "# 'Embarked' is stored as letters, so fit a label encoder to the train set to use in the loop\n",
    "embarked_encoder = LabelEncoder()\n",
    "embarked_encoder.fit(df['Embarked'].fillna('Null'))\n",
    " \n",
    "# Record anyone travelling alone\n",
    "df['Alone'] = (df['SibSp'] == 0) & (df['Parch'] == 0)\n",
    "\n",
    "# Transform 'Embarked'\n",
    "df['Embarked'].fillna('Null', inplace=True)\n",
    "df['Embarked'] = embarked_encoder.transform(df['Embarked'])\n",
    "\n",
    "# Transform 'Sex'\n",
    "df.loc[df['Sex'] == 'female','Sex'] = 0\n",
    "df.loc[df['Sex'] == 'male','Sex'] = 1\n",
    "df['Sex'] = df['Sex'].astype('int8')\n",
    "\n",
    "# Drop features that seem unusable. Save passenger ids if test\n",
    "df.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the label\n",
    "y = df.pop('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a hold out set randomly\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an LGBM dataset for training\n",
    "categorical_features = ['Alone', 'Sex', 'Pclass', 'Embarked']\n",
    "train_data = lgbm.Dataset(data=X_train, label=y_train, categorical_feature=categorical_features, free_raw_data=False)\n",
    "\n",
    "# Create an LGBM dataset from the test\n",
    "test_data = lgbm.Dataset(data=X_test, label=y_test, categorical_feature=categorical_features, free_raw_data=False)\n",
    "\n",
    "# Finally, create a dataset for the FULL training data to give us maximum amount of data to train on after \n",
    "# performance has been calibrate\n",
    "# final_train_set = lgbm.Dataset(data=df, label=y, categorical_feature=categorical_features, free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'boosting': 'dart',          # dart (drop out trees) often performs better\n",
    "    'application': 'binary',     # Binary classification\n",
    "    'learning_rate': 0.05,       # Learning rate, controls size of a gradient descent step\n",
    "    'min_data_in_leaf': 20,      # Data set is quite small so reduce this a bit\n",
    "    'feature_fraction': 0.7,     # Proportion of features in each boost, controls overfitting\n",
    "    'num_leaves': 41,            # Controls size of tree since LGBM uses leaf wise splits\n",
    "    'metric': 'binary_logloss',  # Area under ROC curve as the evaulation metric\n",
    "    'drop_rate': 0.15\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def azure_ml_callback(run):\n",
    "    def callback(env):\n",
    "        if env.evaluation_result_list:\n",
    "            for data_name, eval_name, result, _ in env.evaluation_result_list:\n",
    "                run.log(\"%s (%s)\" % (eval_name, data_name), result)\n",
    "    callback.order = 10\n",
    "    return callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "def log_metrics(clf, X_test, y_test, run):\n",
    "    preds = np.round(clf.predict(X_test))\n",
    "    run.log(\"accuracy (test)\", accuracy_score(y_test, preds))\n",
    "    run.log(\"precision (test)\", precision_score(y_test, preds))\n",
    "    run.log(\"recall (test)\", recall_score(y_test, preds))\n",
    "    run.log(\"f1 (test)\", f1_score(y_test, preds))\n",
    "\n",
    "def log_importance(clf, run, figsize=(9, 5)):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    lgbm.plot_importance(clf, ax=ax)\n",
    "    run.log_image(\"feature importance\", plot=fig)\n",
    "    \n",
    "def register_model(model, run):\n",
    "    output_dir = './outputs'\n",
    "    model_file_name = 'ligbm_titanic.pkl'\n",
    "    model_file_path = os.path.join(output_dir, model_file_name)\n",
    "    joblib.dump(value=model, filename=model_file_path)\n",
    "    run.upload_file('ligbm_titanic.pkl', model_file_path)\n",
    "    return run.register_model(model_name=model_file_name, model_path=model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = {}\n",
    "\n",
    "with exp.start_logging() as run:\n",
    "    clf = lgbm.train(train_set=train_data,\n",
    "                 params=lgbm_params,\n",
    "                 valid_sets=[train_data, test_data], \n",
    "                 valid_names=['train', 'val'],\n",
    "                 evals_result=evaluation_results,\n",
    "                 num_boost_round=500,\n",
    "                 early_stopping_rounds=100,\n",
    "                 verbose_eval=20,\n",
    "                 callbacks = [azure_ml_callback(run)]\n",
    "                )\n",
    "    \n",
    "    log_metrics(clf, X_test, y_test, run)\n",
    "    log_importance(clf, run)\n",
    "    register_model(clf, run)\n",
    "    \n",
    "optimum_boost_rounds = clf.best_iteration"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c39ce73b6d48f343ffd00681afb9b3f63104480cfaffe0ebb445fe41a6801158"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('packt-repo-M2qY5kM-': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
